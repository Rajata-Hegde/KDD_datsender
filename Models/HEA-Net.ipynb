{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":394223,"sourceType":"datasetVersion","datasetId":174616},{"sourceId":14523807,"sourceType":"datasetVersion","datasetId":9276062}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:57:30.176866Z","iopub.execute_input":"2026-01-17T11:57:30.177192Z","iopub.status.idle":"2026-01-17T11:57:30.207055Z","shell.execute_reply.started":"2026-01-17T11:57:30.177145Z","shell.execute_reply":"2026-01-17T11:57:30.206368Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nsl-kdd-augmented/smote_augmented.csv\n/kaggle/input/nslkdd/KDDTest+.arff\n/kaggle/input/nslkdd/KDDTest-21.arff\n/kaggle/input/nslkdd/KDDTest1.jpg\n/kaggle/input/nslkdd/KDDTrain+.txt\n/kaggle/input/nslkdd/KDDTrain+_20Percent.txt\n/kaggle/input/nslkdd/KDDTest-21.txt\n/kaggle/input/nslkdd/KDDTest+.txt\n/kaggle/input/nslkdd/KDDTrain+.arff\n/kaggle/input/nslkdd/index.html\n/kaggle/input/nslkdd/KDDTrain+_20Percent.arff\n/kaggle/input/nslkdd/KDDTrain1.jpg\n/kaggle/input/nslkdd/nsl-kdd/KDDTest+.arff\n/kaggle/input/nslkdd/nsl-kdd/KDDTest-21.arff\n/kaggle/input/nslkdd/nsl-kdd/KDDTest1.jpg\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+_20Percent.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTest-21.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTest+.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+.arff\n/kaggle/input/nslkdd/nsl-kdd/index.html\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+_20Percent.arff\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain1.jpg\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n# ===========================================\n# 1️⃣ The Micro-Specialist (The \"Small Model\")\n# ===========================================\n# This model is a specialist in R2L/U2R patterns. \n# We'll use your best performing neural specialist instance here.\ndef hea_fusion_inference(X_proc, df_orig):\n    model_sp.eval() \n    with torch.no_grad():\n        logits, _ = model_sp(torch.tensor(X_proc, dtype=torch.float32).to(device))\n        probs_sp = torch.softmax(logits * 2.0, dim=1).cpu().numpy()\n    \n    probs_xgb = expert.predict_proba(X_proc)\n    final_preds = []\n    \n    # Pre-define class indices\n    idx_normal = le.transform(['normal'])[0]\n    idx_back = le.transform(['back'])[0]\n    idx_guess = le.transform(['guess_passwd'])[0]\n    idx_warez = le.transform(['warezmaster'])[0]\n\n    for i in range(len(X_proc)):\n        p_x = probs_xgb[i]\n        p_s = probs_sp[i]\n        \n        # --- LEVEL 1: PROTOCOL ANCHORS (Protecting the Stability) ---\n        # If it's a high-confidence DoS/Probe, don't let the Specialist touch it.\n        # This fixes the 'back' recall drop.\n        if (p_x[idx_back] > 0.3 and df_orig['src_bytes'].iloc[i] > 5000) or \\\n           (le.classes_[np.argmax(p_x)] in ['neptune', 'smurf', 'satan', 'ipsweep'] and np.max(p_x) > 0.8):\n            final_preds.append(np.argmax(p_x))\n            continue\n\n        # --- LEVEL 2: THE STATEFUL SIEVE (The \"Small Model\" Logic) ---\n        # If login/content flags are tripped, we FORCE an attack prediction.\n        is_content_attack = (df_orig['hot'].iloc[i] > 0) or \\\n                            (df_orig['num_failed_logins'].iloc[i] > 0) or \\\n                            (df_orig['is_guest_login'].iloc[i] > 0) or \\\n                            (df_orig['num_compromised'].iloc[i] > 0)\n        \n        if is_content_attack:\n            # We MASK the 'normal' class. The Specialist MUST find the attack.\n            p_s_masked = p_s.copy()\n            p_s_masked[idx_normal] = 0\n            # Also mask DoS to prevent collision in this branch\n            dos_indices = [le.transform([c])[0] for c in ['neptune', 'back', 'land', 'pod', 'smurf', 'teardrop']]\n            p_s_masked[dos_indices] = 0\n            \n            final_preds.append(np.argmax(p_s_masked))\n            continue\n\n        # --- LEVEL 3: RESIDUAL STABILITY ---\n        # If XGBoost is very sure about 'Normal', trust it.\n        if p_x[idx_normal] > 0.95:\n            final_preds.append(idx_normal)\n        else:\n            # Default to the most likely prediction between the two\n            final_preds.append(np.argmax(0.6 * p_x + 0.4 * p_s))\n            \n    return np.array(final_preds)\n\n# ===========================================\n# 2️⃣ Final Execution\n# ===========================================\nprint(\"Executing HEA-Net Final Fusion...\")\nfinal_preds = hea_fusion_inference(X_test_proc, df_test)\n\nunique_labels = np.unique(np.concatenate([y_test_enc, final_preds]))\ntarget_names = [le.classes_[i] for i in unique_labels]\n\nprint(\"\\n--- HEA-Net Q1 FINAL RESULTS ---\")\nprint(classification_report(y_test_enc, final_preds, \n                            labels=unique_labels, \n                            target_names=target_names, \n                            zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:41:47.211936Z","iopub.execute_input":"2026-01-17T13:41:47.212307Z","iopub.status.idle":"2026-01-17T13:41:48.439989Z","shell.execute_reply.started":"2026-01-17T13:41:47.212277Z","shell.execute_reply":"2026-01-17T13:41:48.439103Z"}},"outputs":[{"name":"stdout","text":"Executing HEA-Net Final Fusion...\n\n--- HEA-Net Q1 FINAL RESULTS ---\n                 precision    recall  f1-score   support\n\n           back       0.98      0.95      0.97       359\nbuffer_overflow       0.22      0.40      0.28        20\n      ftp_write       0.04      0.33      0.07         3\n   guess_passwd       0.71      0.25      0.37      1231\n           imap       0.00      0.00      0.00         1\n        ipsweep       0.99      0.98      0.98       141\n           land       0.00      0.00      0.00         7\n     loadmodule       0.00      0.00      0.00         2\n       multihop       0.00      0.00      0.00        18\n        neptune       1.00      1.00      1.00      4657\n           nmap       0.99      1.00      0.99        73\n         normal       0.89      0.97      0.93      9711\n           perl       0.00      0.00      0.00         2\n            phf       0.00      0.00      0.00         2\n            pod       0.72      0.93      0.81        41\n      portsweep       0.79      0.92      0.85       157\n        rootkit       0.02      0.23      0.03        13\n          satan       0.83      1.00      0.91       735\n          smurf       1.00      1.00      1.00       665\n       teardrop       0.24      1.00      0.39        12\n    warezclient       0.00      0.00      0.00         0\n    warezmaster       0.92      0.44      0.60       944\n\n       accuracy                           0.90     18794\n      macro avg       0.47      0.52      0.46     18794\n   weighted avg       0.91      0.90      0.89     18794\n\n","output_type":"stream"}],"execution_count":61}]}