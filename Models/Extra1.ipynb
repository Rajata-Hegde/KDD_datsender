{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":394223,"sourceType":"datasetVersion","datasetId":174616},{"sourceId":14523807,"sourceType":"datasetVersion","datasetId":9276062}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T09:11:53.294826Z","iopub.execute_input":"2026-01-17T09:11:53.295463Z","iopub.status.idle":"2026-01-17T09:11:53.572889Z","shell.execute_reply.started":"2026-01-17T09:11:53.295433Z","shell.execute_reply":"2026-01-17T09:11:53.572109Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nsl-kdd-augmented/smote_augmented.csv\n/kaggle/input/nslkdd/KDDTest+.arff\n/kaggle/input/nslkdd/KDDTest-21.arff\n/kaggle/input/nslkdd/KDDTest1.jpg\n/kaggle/input/nslkdd/KDDTrain+.txt\n/kaggle/input/nslkdd/KDDTrain+_20Percent.txt\n/kaggle/input/nslkdd/KDDTest-21.txt\n/kaggle/input/nslkdd/KDDTest+.txt\n/kaggle/input/nslkdd/KDDTrain+.arff\n/kaggle/input/nslkdd/index.html\n/kaggle/input/nslkdd/KDDTrain+_20Percent.arff\n/kaggle/input/nslkdd/KDDTrain1.jpg\n/kaggle/input/nslkdd/nsl-kdd/KDDTest+.arff\n/kaggle/input/nslkdd/nsl-kdd/KDDTest-21.arff\n/kaggle/input/nslkdd/nsl-kdd/KDDTest1.jpg\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+_20Percent.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTest-21.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTest+.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+.arff\n/kaggle/input/nslkdd/nsl-kdd/index.html\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+_20Percent.arff\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain1.jpg\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import QuantileTransformer, LabelEncoder\nfrom sklearn.metrics import classification_report, f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tqdm import tqdm\nimport math\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {DEVICE}\")\n\ncolumns = [\n    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land',\n    'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n    'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n    'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n    'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n    'outcome', 'level'\n]\n\n# ===========================================\n# DATA PREPROCESSING\n# ===========================================\ndf_train = pd.read_csv(\"/kaggle/input/nsl-kdd-augmented/smote_augmented.csv\") \ndf_test = pd.read_csv(\"/kaggle/input/nslkdd/KDDTest+.txt\", header=None)\ndf_test.columns = columns\n\ntrain_labels = set(df_train['outcome'].unique())\ndf_test = df_test[df_test['outcome'].isin(train_labels)].reset_index(drop=True)\n\ncat_cols = ['protocol_type', 'service', 'flag']\nnum_cols = [c for c in df_train.columns if c not in cat_cols + ['outcome', 'level']]\n\n# Label encoding with careful test set handling\ncat_dims = []\nfor col in cat_cols:\n    le_c = LabelEncoder()\n    df_train[col] = le_c.fit_transform(df_train[col].astype(str))\n    train_classes = {cls: i for i, cls in enumerate(le_c.classes_)}\n    df_test[col] = df_test[col].map(lambda x: train_classes.get(str(x), 0))\n    cat_dims.append(len(le_c.classes_))\n\n# Quantile transformation\nqt = QuantileTransformer(output_distribution='normal', random_state=42)\nX_train_num = qt.fit_transform(df_train[num_cols]).astype(np.float32)\nX_test_num = qt.transform(df_test[num_cols]).astype(np.float32)\n\nle_target = LabelEncoder()\ny_train = le_target.fit_transform(df_train['outcome'])\ny_test = le_target.transform(df_test['outcome'])\n\n# Compute class weights for focal loss\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n\nprint(f\"Number of classes: {len(le_target.classes_)}\")\nprint(f\"Training samples: {len(y_train)}, Test samples: {len(y_test)}\")\n\n# ===========================================\n# NOVEL ARCHITECTURE: HCAN\n# Hierarchical Class-Aware Network with Multi-Scale Attention\n# ===========================================\n\nclass AdaptiveFeatureGate(nn.Module):\n    \"\"\"Dynamic feature selection with learnable thresholds\"\"\"\n    def __init__(self, dim):\n        super().__init__()\n        self.gate_weight = nn.Parameter(torch.ones(dim))\n        self.gate_bias = nn.Parameter(torch.zeros(dim))\n        self.threshold = nn.Parameter(torch.tensor(0.5))\n        \n    def forward(self, x):\n        importance = torch.sigmoid(x * self.gate_weight + self.gate_bias)\n        mask = (importance > self.threshold).float()\n        # Straight-through estimator for gradients\n        mask = mask - importance.detach() + importance\n        return x * mask\n\nclass MultiScaleFeatureExtractor(nn.Module):\n    \"\"\"Extract features at multiple temporal scales\"\"\"\n    def __init__(self, input_dim, hidden_dim):\n        super().__init__()\n        self.scales = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.LayerNorm(hidden_dim),\n                nn.GELU(),\n                nn.Dropout(0.2)\n            ) for _ in range(3)\n        ])\n        self.fusion = nn.Linear(hidden_dim * 3, hidden_dim)\n        \n    def forward(self, x):\n        features = [scale(x) for scale in self.scales]\n        combined = torch.cat(features, dim=-1)\n        return self.fusion(combined)\n\nclass ClassPrototypeAttention(nn.Module):\n    \"\"\"Learn class prototypes and compute attention-weighted representations\"\"\"\n    def __init__(self, dim, num_classes):\n        super().__init__()\n        # Learnable class prototypes\n        self.prototypes = nn.Parameter(torch.randn(num_classes, dim))\n        self.query = nn.Linear(dim, dim)\n        self.key = nn.Linear(dim, dim)\n        self.value = nn.Linear(dim, dim)\n        self.scale = math.sqrt(dim)\n        \n    def forward(self, x):\n        # x: [batch, dim]\n        q = self.query(x)  # [batch, dim]\n        k = self.key(self.prototypes)  # [num_classes, dim]\n        v = self.value(self.prototypes)  # [num_classes, dim]\n        \n        # Compute attention scores\n        scores = torch.matmul(q, k.t()) / self.scale  # [batch, num_classes]\n        attn_weights = F.softmax(scores, dim=-1)\n        \n        # Weighted combination of prototypes\n        attended = torch.matmul(attn_weights, v)  # [batch, dim]\n        return attended, attn_weights\n\nclass ResidualBlock(nn.Module):\n    \"\"\"Residual block with layer normalization\"\"\"\n    def __init__(self, dim, dropout=0.3):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, dim * 2),\n            nn.LayerNorm(dim * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(dim * 2, dim),\n            nn.LayerNorm(dim),\n            nn.Dropout(dropout)\n        )\n        \n    def forward(self, x):\n        return x + self.net(x)\n\nclass HCAN(nn.Module):\n    \"\"\"\n    Hierarchical Class-Aware Network\n    \n    Novel contributions:\n    1. Multi-scale feature extraction at different granularities\n    2. Class prototype attention mechanism for better rare class recognition\n    3. Adaptive feature gating to handle noisy features\n    4. Hierarchical fusion of categorical and numerical streams\n    5. Deep residual pathway for gradient flow\n    \"\"\"\n    def __init__(self, cat_dims, num_feat_dim, num_classes, emb_dim=128, hidden_dim=256):\n        super().__init__()\n        self.num_classes = num_classes\n        \n        # === Categorical Stream ===\n        self.cat_embeddings = nn.ModuleList([\n            nn.Embedding(d, emb_dim) for d in cat_dims\n        ])\n        self.cat_projection = nn.Sequential(\n            nn.Linear(emb_dim * len(cat_dims), hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.GELU(),\n            nn.Dropout(0.3)\n        )\n        \n        # === Numerical Stream with Multi-Scale Processing ===\n        self.num_gate = AdaptiveFeatureGate(num_feat_dim)\n        self.multi_scale = MultiScaleFeatureExtractor(num_feat_dim, hidden_dim)\n        \n        # === Feature Fusion ===\n        self.fusion = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.GELU(),\n            nn.Dropout(0.3)\n        )\n        \n        # === Deep Residual Pathway ===\n        self.residual_blocks = nn.ModuleList([\n            ResidualBlock(hidden_dim, dropout=0.3) for _ in range(3)\n        ])\n        \n        # === Class Prototype Attention ===\n        self.prototype_attn = ClassPrototypeAttention(hidden_dim, num_classes)\n        \n        # === Final Classification Head ===\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.GELU(),\n            nn.Dropout(0.4),\n            nn.Linear(hidden_dim, num_classes)\n        )\n        \n        self._init_weights()\n        \n    def _init_weights(self):\n        \"\"\"Custom initialization for better convergence\"\"\"\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Embedding):\n                nn.init.normal_(m.weight, mean=0, std=0.02)\n                \n    def forward(self, x_cat, x_num):\n        # Categorical stream\n        cat_embeds = [emb(x_cat[:, i]) for i, emb in enumerate(self.cat_embeddings)]\n        cat_features = torch.cat(cat_embeds, dim=-1)\n        cat_features = self.cat_projection(cat_features)\n        \n        # Numerical stream with adaptive gating\n        num_gated = self.num_gate(x_num)\n        num_features = self.multi_scale(num_gated)\n        \n        # Fusion\n        fused = self.fusion(torch.cat([cat_features, num_features], dim=-1))\n        \n        # Deep residual processing\n        for block in self.residual_blocks:\n            fused = block(fused)\n        \n        # Class prototype attention\n        prototype_features, attn_weights = self.prototype_attn(fused)\n        \n        # Combine original features with prototype-attended features\n        final_features = torch.cat([fused, prototype_features], dim=-1)\n        \n        # Classification\n        logits = self.classifier(final_features)\n        \n        return logits, attn_weights\n\n# ===========================================\n# ADVANCED LOSS FUNCTIONS\n# ===========================================\n\nclass FocalLoss(nn.Module):\n    \"\"\"Focal Loss for addressing class imbalance\"\"\"\n    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n        \n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n        pt = torch.exp(-ce_loss)\n        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n        \n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        else:\n            return focal_loss\n\nclass PrototypeLoss(nn.Module):\n    \"\"\"Auxiliary loss to ensure prototypes are well-separated\"\"\"\n    def __init__(self, margin=1.0):\n        super().__init__()\n        self.margin = margin\n        \n    def forward(self, prototypes):\n        # Compute pairwise distances\n        dist_matrix = torch.cdist(prototypes, prototypes, p=2)\n        # Mask diagonal\n        mask = ~torch.eye(len(prototypes), dtype=bool, device=prototypes.device)\n        distances = dist_matrix[mask]\n        # Encourage minimum margin between prototypes\n        loss = F.relu(self.margin - distances).mean()\n        return loss\n\nclass CombinedLoss(nn.Module):\n    \"\"\"Combined loss with multiple objectives\"\"\"\n    def __init__(self, alpha, num_classes):\n        super().__init__()\n        self.focal = FocalLoss(alpha=alpha, gamma=2.5)\n        self.proto = PrototypeLoss(margin=1.5)\n        \n    def forward(self, logits, targets, prototypes):\n        focal_loss = self.focal(logits, targets)\n        proto_loss = self.proto(prototypes)\n        return focal_loss + 0.1 * proto_loss, focal_loss, proto_loss\n\n# ===========================================\n# DATASET AND TRAINING\n# ===========================================\n\nclass NSLDataset(Dataset):\n    def __init__(self, c, n, y):\n        self.c = torch.tensor(c, dtype=torch.long)\n        self.n = torch.tensor(n, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, i):\n        return self.c[i], self.n[i], self.y[i]\n\n# Create data loaders\ntrain_dataset = NSLDataset(df_train[cat_cols].values, X_train_num, y_train)\ntest_dataset = NSLDataset(df_test[cat_cols].values, X_test_num, y_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=2)\n\n# Initialize model\nmodel = HCAN(\n    cat_dims=cat_dims,\n    num_feat_dim=X_train_num.shape[1],\n    num_classes=len(le_target.classes_),\n    emb_dim=128,\n    hidden_dim=256\n).to(DEVICE)\n\nprint(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n# Optimizer with weight decay\noptimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=1e-3,\n    weight_decay=1e-4,\n    betas=(0.9, 0.999)\n)\n\n# Learning rate scheduler\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n    optimizer, T_0=10, T_mult=2, eta_min=1e-6\n)\n\n# Loss function\ncriterion = CombinedLoss(alpha=class_weights, num_classes=len(le_target.classes_))\n\n# ===========================================\n# TRAINING LOOP\n# ===========================================\n\nbest_macro_f1 = 0.0\npatience = 15\npatience_counter = 0\n\nfor epoch in range(50):\n    # Training\n    model.train()\n    train_loss = 0\n    train_focal = 0\n    train_proto = 0\n    \n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/50\")\n    for xc, xn, y in pbar:\n        xc, xn, y = xc.to(DEVICE), xn.to(DEVICE), y.to(DEVICE)\n        \n        optimizer.zero_grad()\n        logits, _ = model(xc, xn)\n        \n        loss, focal_loss, proto_loss = criterion(\n            logits, y, model.prototype_attn.prototypes\n        )\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        train_loss += loss.item()\n        train_focal += focal_loss.item()\n        train_proto += proto_loss.item()\n        \n        pbar.set_postfix({\n            'loss': f'{loss.item():.4f}',\n            'lr': f'{optimizer.param_groups[0][\"lr\"]:.6f}'\n        })\n    \n    scheduler.step()\n    \n    avg_loss = train_loss / len(train_loader)\n    avg_focal = train_focal / len(train_loader)\n    avg_proto = train_proto / len(train_loader)\n    \n    # Validation\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for xc, xn, y in test_loader:\n            xc, xn = xc.to(DEVICE), xn.to(DEVICE)\n            logits, _ = model(xc, xn)\n            preds = torch.argmax(logits, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y.numpy())\n    \n    # Calculate metrics\n    macro_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n    weighted_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n    \n    print(f\"\\nEpoch {epoch+1}:\")\n    print(f\"  Train Loss: {avg_loss:.4f} (Focal: {avg_focal:.4f}, Proto: {avg_proto:.4f})\")\n    print(f\"  Macro F1: {macro_f1:.4f} | Weighted F1: {weighted_f1:.4f}\")\n    \n    # Early stopping\n    if macro_f1 > best_macro_f1:\n        best_macro_f1 = macro_f1\n        patience_counter = 0\n        torch.save(model.state_dict(), 'best_hcan_model.pth')\n        print(f\"  ✓ New best Macro F1: {best_macro_f1:.4f}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n            break\n\n# ===========================================\n# FINAL EVALUATION\n# ===========================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING BEST MODEL FOR FINAL EVALUATION\")\nprint(\"=\"*60)\n\nmodel.load_state_dict(torch.load('best_hcan_model.pth'))\nmodel.eval()\n\nall_preds = []\nall_labels = []\nall_probs = []\n\nwith torch.no_grad():\n    for xc, xn, y in test_loader:\n        xc, xn = xc.to(DEVICE), xn.to(DEVICE)\n        logits, _ = model(xc, xn)\n        probs = F.softmax(logits, dim=1)\n        preds = torch.argmax(logits, dim=1)\n        \n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(y.numpy())\n        all_probs.extend(probs.cpu().numpy())\n\nprint(\"\\nFINAL CLASSIFICATION REPORT:\")\nprint(\"=\"*60)\nprint(classification_report(\n    all_labels, \n    all_preds, \n    target_names=le_target.classes_, \n    zero_division=0,\n    digits=4\n))\n\n# Calculate per-class F1 scores\nfrom sklearn.metrics import f1_score\nper_class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\nprint(\"\\nPER-CLASS F1 SCORES:\")\nprint(\"=\"*60)\nfor class_name, f1 in zip(le_target.classes_, per_class_f1):\n    print(f\"{class_name:20s}: {f1:.4f}\")\n\nprint(f\"\\n{'='*60}\")\nprint(f\"BEST MACRO F1 ACHIEVED: {best_macro_f1:.4f}\")\nprint(f\"{'='*60}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:04:45.115959Z","iopub.execute_input":"2026-01-17T10:04:45.116329Z","iopub.status.idle":"2026-01-17T10:20:39.294791Z","shell.execute_reply.started":"2026-01-17T10:04:45.116298Z","shell.execute_reply":"2026-01-17T10:20:39.293790Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nNumber of classes: 23\nTraining samples: 557934, Test samples: 18794\nModel parameters: 1,604,452\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/50: 100%|██████████| 2180/2180 [00:27<00:00, 80.21it/s, loss=0.0577, lr=0.001000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1:\n  Train Loss: 0.1422 (Focal: 0.1422, Proto: 0.0000)\n  Macro F1: 0.4212 | Weighted F1: 0.8251\n  ✓ New best Macro F1: 0.4212\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/50: 100%|██████████| 2180/2180 [00:26<00:00, 80.99it/s, loss=0.0385, lr=0.000976]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2:\n  Train Loss: 0.0513 (Focal: 0.0513, Proto: 0.0000)\n  Macro F1: 0.4248 | Weighted F1: 0.8129\n  ✓ New best Macro F1: 0.4248\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.44it/s, loss=0.0536, lr=0.000905]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3:\n  Train Loss: 0.0419 (Focal: 0.0419, Proto: 0.0000)\n  Macro F1: 0.4026 | Weighted F1: 0.8094\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.07it/s, loss=0.1007, lr=0.000794]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4:\n  Train Loss: 0.0427 (Focal: 0.0427, Proto: 0.0000)\n  Macro F1: 0.4129 | Weighted F1: 0.8064\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.35it/s, loss=0.0211, lr=0.000655]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5:\n  Train Loss: 0.0374 (Focal: 0.0374, Proto: 0.0000)\n  Macro F1: 0.4280 | Weighted F1: 0.8167\n  ✓ New best Macro F1: 0.4280\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.50it/s, loss=0.0257, lr=0.000501]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6:\n  Train Loss: 0.0320 (Focal: 0.0320, Proto: 0.0000)\n  Macro F1: 0.4047 | Weighted F1: 0.8092\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/50: 100%|██████████| 2180/2180 [00:26<00:00, 80.79it/s, loss=0.0243, lr=0.000346]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7:\n  Train Loss: 0.0274 (Focal: 0.0274, Proto: 0.0000)\n  Macro F1: 0.4194 | Weighted F1: 0.7993\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.23it/s, loss=0.0187, lr=0.000207]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8:\n  Train Loss: 0.0243 (Focal: 0.0243, Proto: 0.0000)\n  Macro F1: 0.4205 | Weighted F1: 0.8087\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.29it/s, loss=0.0055, lr=0.000096]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9:\n  Train Loss: 0.0226 (Focal: 0.0226, Proto: 0.0000)\n  Macro F1: 0.4210 | Weighted F1: 0.8036\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.31it/s, loss=0.0472, lr=0.000025]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10:\n  Train Loss: 0.0215 (Focal: 0.0215, Proto: 0.0000)\n  Macro F1: 0.4248 | Weighted F1: 0.8077\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/50: 100%|██████████| 2180/2180 [00:26<00:00, 80.98it/s, loss=0.0564, lr=0.001000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11:\n  Train Loss: 0.0375 (Focal: 0.0375, Proto: 0.0000)\n  Macro F1: 0.4184 | Weighted F1: 0.7966\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.56it/s, loss=0.0372, lr=0.000994]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12:\n  Train Loss: 0.0367 (Focal: 0.0367, Proto: 0.0000)\n  Macro F1: 0.4132 | Weighted F1: 0.8043\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.95it/s, loss=0.0400, lr=0.000976]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13:\n  Train Loss: 0.0301 (Focal: 0.0301, Proto: 0.0000)\n  Macro F1: 0.4283 | Weighted F1: 0.8145\n  ✓ New best Macro F1: 0.4283\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.67it/s, loss=0.0095, lr=0.000946]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14:\n  Train Loss: 0.0278 (Focal: 0.0278, Proto: 0.0000)\n  Macro F1: 0.4220 | Weighted F1: 0.8144\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.71it/s, loss=0.0137, lr=0.000905]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15:\n  Train Loss: 0.0256 (Focal: 0.0256, Proto: 0.0000)\n  Macro F1: 0.4129 | Weighted F1: 0.8007\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.75it/s, loss=0.0184, lr=0.000854]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16:\n  Train Loss: 0.0245 (Focal: 0.0245, Proto: 0.0000)\n  Macro F1: 0.4151 | Weighted F1: 0.8030\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.41it/s, loss=0.0060, lr=0.000794]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17:\n  Train Loss: 0.0229 (Focal: 0.0229, Proto: 0.0000)\n  Macro F1: 0.4165 | Weighted F1: 0.8024\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/50: 100%|██████████| 2180/2180 [00:26<00:00, 80.90it/s, loss=0.0163, lr=0.000727]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18:\n  Train Loss: 0.0212 (Focal: 0.0212, Proto: 0.0000)\n  Macro F1: 0.4177 | Weighted F1: 0.8034\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.15it/s, loss=0.0078, lr=0.000655]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19:\n  Train Loss: 0.0204 (Focal: 0.0204, Proto: 0.0000)\n  Macro F1: 0.4236 | Weighted F1: 0.8070\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.26it/s, loss=0.0026, lr=0.000579]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20:\n  Train Loss: 0.0193 (Focal: 0.0193, Proto: 0.0000)\n  Macro F1: 0.4325 | Weighted F1: 0.7995\n  ✓ New best Macro F1: 0.4325\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.40it/s, loss=0.0069, lr=0.000501]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 21:\n  Train Loss: 0.0181 (Focal: 0.0181, Proto: 0.0000)\n  Macro F1: 0.4102 | Weighted F1: 0.7973\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.79it/s, loss=0.0083, lr=0.000422]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 22:\n  Train Loss: 0.0173 (Focal: 0.0173, Proto: 0.0000)\n  Macro F1: 0.4221 | Weighted F1: 0.8045\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.21it/s, loss=0.0086, lr=0.000346]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23:\n  Train Loss: 0.0163 (Focal: 0.0163, Proto: 0.0000)\n  Macro F1: 0.4274 | Weighted F1: 0.8097\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.71it/s, loss=0.0077, lr=0.000274]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 24:\n  Train Loss: 0.0156 (Focal: 0.0156, Proto: 0.0000)\n  Macro F1: 0.4221 | Weighted F1: 0.8082\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/50: 100%|██████████| 2180/2180 [00:26<00:00, 80.76it/s, loss=0.0026, lr=0.000207]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25:\n  Train Loss: 0.0148 (Focal: 0.0148, Proto: 0.0000)\n  Macro F1: 0.4204 | Weighted F1: 0.8035\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.20it/s, loss=0.0062, lr=0.000147]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26:\n  Train Loss: 0.0142 (Focal: 0.0142, Proto: 0.0000)\n  Macro F1: 0.4294 | Weighted F1: 0.8076\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.42it/s, loss=0.0077, lr=0.000096]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 27:\n  Train Loss: 0.0137 (Focal: 0.0137, Proto: 0.0000)\n  Macro F1: 0.4288 | Weighted F1: 0.8053\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/50: 100%|██████████| 2180/2180 [00:26<00:00, 80.82it/s, loss=0.0317, lr=0.000055]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28:\n  Train Loss: 0.0146 (Focal: 0.0146, Proto: 0.0000)\n  Macro F1: 0.4240 | Weighted F1: 0.8058\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.53it/s, loss=0.0260, lr=0.000025]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29:\n  Train Loss: 0.0132 (Focal: 0.0132, Proto: 0.0000)\n  Macro F1: 0.4224 | Weighted F1: 0.8068\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.41it/s, loss=0.0050, lr=0.000007]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30:\n  Train Loss: 0.0129 (Focal: 0.0129, Proto: 0.0000)\n  Macro F1: 0.4236 | Weighted F1: 0.8052\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.23it/s, loss=0.0206, lr=0.001000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 31:\n  Train Loss: 0.0282 (Focal: 0.0282, Proto: 0.0000)\n  Macro F1: 0.4184 | Weighted F1: 0.8078\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.79it/s, loss=0.0089, lr=0.000998]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 32:\n  Train Loss: 0.0245 (Focal: 0.0245, Proto: 0.0000)\n  Macro F1: 0.4177 | Weighted F1: 0.8122\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.95it/s, loss=0.0084, lr=0.000994]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 33:\n  Train Loss: 0.0247 (Focal: 0.0247, Proto: 0.0000)\n  Macro F1: 0.4296 | Weighted F1: 0.8156\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/50: 100%|██████████| 2180/2180 [00:26<00:00, 81.10it/s, loss=0.0143, lr=0.000986]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 34:\n  Train Loss: 0.0234 (Focal: 0.0234, Proto: 0.0000)\n  Macro F1: 0.4294 | Weighted F1: 0.8145\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/50: 100%|██████████| 2180/2180 [00:26<00:00, 82.12it/s, loss=0.0233, lr=0.000976]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 35:\n  Train Loss: 0.0225 (Focal: 0.0225, Proto: 0.0000)\n  Macro F1: 0.4249 | Weighted F1: 0.8199\n\nEarly stopping at epoch 35\n\n============================================================\nLOADING BEST MODEL FOR FINAL EVALUATION\n============================================================\n\nFINAL CLASSIFICATION REPORT:\n============================================================\n                 precision    recall  f1-score   support\n\n           back     0.9301    1.0000    0.9638       359\nbuffer_overflow     0.5714    0.2000    0.2963        20\n      ftp_write     0.0000    0.0000    0.0000         3\n   guess_passwd     0.8000    0.0032    0.0065      1231\n           imap     0.0000    0.0000    0.0000         1\n        ipsweep     0.9079    0.9787    0.9420       141\n           land     1.0000    1.0000    1.0000         7\n     loadmodule     0.0000    0.0000    0.0000         2\n       multihop     0.0000    0.0000    0.0000        18\n        neptune     0.9991    0.9811    0.9900      4657\n           nmap     0.7826    0.9863    0.8727        73\n         normal     0.8523    0.9139    0.8820      9711\n           perl     0.2500    0.5000    0.3333         2\n            phf     0.0714    0.5000    0.1250         2\n            pod     0.6226    0.8049    0.7021        41\n      portsweep     0.7778    0.9363    0.8497       157\n        rootkit     0.0137    0.0769    0.0233        13\n          satan     0.7484    0.9469    0.8360       735\n          smurf     0.6073    1.0000    0.7557       665\n            spy     0.0000    0.0000    0.0000         0\n       teardrop     0.2292    0.9167    0.3667        12\n    warezclient     0.0000    0.0000    0.0000         0\n    warezmaster     0.1429    0.0011    0.0021       944\n\n       accuracy                         0.8292     18794\n      macro avg     0.4481    0.5107    0.4325     18794\n   weighted avg     0.8349    0.8292    0.7995     18794\n\n\nPER-CLASS F1 SCORES:\n============================================================\nback                : 0.9638\nbuffer_overflow     : 0.2963\nftp_write           : 0.0000\nguess_passwd        : 0.0065\nimap                : 0.0000\nipsweep             : 0.9420\nland                : 1.0000\nloadmodule          : 0.0000\nmultihop            : 0.0000\nneptune             : 0.9900\nnmap                : 0.8727\nnormal              : 0.8820\nperl                : 0.3333\nphf                 : 0.1250\npod                 : 0.7021\nportsweep           : 0.8497\nrootkit             : 0.0233\nsatan               : 0.8360\nsmurf               : 0.7557\nspy                 : 0.0000\nteardrop            : 0.3667\nwarezclient         : 0.0000\nwarezmaster         : 0.0021\n\n============================================================\nBEST MACRO F1 ACHIEVED: 0.4325\n============================================================\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom sklearn.preprocessing import QuantileTransformer, LabelEncoder, StandardScaler\nfrom sklearn.metrics import classification_report, f1_score, confusion_matrix\nfrom tqdm import tqdm\nimport math\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {DEVICE}\")\n\ncolumns = [\n    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land',\n    'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n    'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n    'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n    'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n    'outcome', 'level'\n]\n\n# ===========================================\n# ENHANCED DATA PREPROCESSING\n# ===========================================\ndf_train = pd.read_csv(\"/kaggle/input/nsl-kdd-augmented/smote_augmented.csv\") \ndf_test = pd.read_csv(\"/kaggle/input/nslkdd/KDDTest+.txt\", header=None)\ndf_test.columns = columns\n\ntrain_labels = set(df_train['outcome'].unique())\ndf_test = df_test[df_test['outcome'].isin(train_labels)].reset_index(drop=True)\n\ncat_cols = ['protocol_type', 'service', 'flag']\nnum_cols = [c for c in df_train.columns if c not in cat_cols + ['outcome', 'level']]\n\n# Label encoding\ncat_dims = []\nfor col in cat_cols:\n    le_c = LabelEncoder()\n    df_train[col] = le_c.fit_transform(df_train[col].astype(str))\n    train_classes = {cls: i for i, cls in enumerate(le_c.classes_)}\n    df_test[col] = df_test[col].map(lambda x: train_classes.get(str(x), 0))\n    cat_dims.append(len(le_c.classes_))\n\n# CRITICAL: Use StandardScaler instead of QuantileTransformer for better rare class separation\nscaler = StandardScaler()\nX_train_num = scaler.fit_transform(df_train[num_cols]).astype(np.float32)\nX_test_num = scaler.transform(df_test[num_cols]).astype(np.float32)\n\nle_target = LabelEncoder()\ny_train = le_target.fit_transform(df_train['outcome'])\ny_test = le_target.transform(df_test['outcome'])\n\n# Compute effective number of samples per class for CB loss\nclass_counts = np.bincount(y_train)\nprint(\"\\nClass distribution in training:\")\nfor i, (name, count) in enumerate(zip(le_target.classes_, class_counts)):\n    print(f\"{name:20s}: {count:8d} samples\")\n\n# ===========================================\n# NOVEL ARCHITECTURE: MC-DPAN\n# Multi-Expert Class-Discriminative Prototype Alignment Network\n# ===========================================\n\nclass ExpertMixture(nn.Module):\n    \"\"\"Multiple expert networks, each specializing in different class groups\"\"\"\n    def __init__(self, input_dim, hidden_dim, num_experts=4):\n        super().__init__()\n        self.num_experts = num_experts\n        self.experts = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.LayerNorm(hidden_dim),\n                nn.GELU(),\n                nn.Dropout(0.2),\n                nn.Linear(hidden_dim, hidden_dim),\n                nn.LayerNorm(hidden_dim),\n                nn.GELU()\n            ) for _ in range(num_experts)\n        ])\n        # Gating network to route inputs to experts\n        self.gate = nn.Sequential(\n            nn.Linear(input_dim, num_experts),\n            nn.Softmax(dim=-1)\n        )\n        \n    def forward(self, x):\n        # Compute gating weights\n        gate_weights = self.gate(x)  # [batch, num_experts]\n        \n        # Get outputs from all experts\n        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=1)  # [batch, num_experts, hidden]\n        \n        # Weighted combination\n        output = torch.einsum('be,beh->bh', gate_weights, expert_outputs)\n        return output, gate_weights\n\nclass PrototypeLayer(nn.Module):\n    \"\"\"Learnable prototypes with distance-based similarity\"\"\"\n    def __init__(self, num_classes, feature_dim):\n        super().__init__()\n        self.prototypes = nn.Parameter(torch.randn(num_classes, feature_dim))\n        nn.init.orthogonal_(self.prototypes)\n        self.scale = nn.Parameter(torch.tensor(10.0))\n        \n    def forward(self, x):\n        # Normalize features and prototypes for cosine similarity\n        x_norm = F.normalize(x, p=2, dim=1)\n        p_norm = F.normalize(self.prototypes, p=2, dim=1)\n        \n        # Cosine similarity (higher is more similar)\n        similarities = torch.matmul(x_norm, p_norm.t()) * self.scale\n        return similarities\n\nclass ContrastiveHead(nn.Module):\n    \"\"\"Supervised contrastive learning head\"\"\"\n    def __init__(self, input_dim, projection_dim=128):\n        super().__init__()\n        self.projector = nn.Sequential(\n            nn.Linear(input_dim, input_dim),\n            nn.ReLU(),\n            nn.Linear(input_dim, projection_dim)\n        )\n        \n    def forward(self, x):\n        return F.normalize(self.projector(x), p=2, dim=1)\n\nclass MCDPAN(nn.Module):\n    \"\"\"\n    Multi-Expert Class-Discriminative Prototype Alignment Network\n    \n    Novel Contributions:\n    1. Mixture of Experts for capturing diverse attack patterns\n    2. Orthogonal prototype initialization for better class separation\n    3. Dual-head design: prototype matching + contrastive learning\n    4. Multi-scale categorical embedding fusion\n    5. Attention-based feature recalibration\n    \"\"\"\n    def __init__(self, cat_dims, num_feat_dim, num_classes, emb_dim=64, hidden_dim=512):\n        super().__init__()\n        self.num_classes = num_classes\n        \n        # === Categorical Embeddings with Different Scales ===\n        self.embeddings = nn.ModuleList([\n            nn.Embedding(d, emb_dim) for d in cat_dims\n        ])\n        cat_total_dim = emb_dim * len(cat_dims)\n        \n        # === Categorical Processing ===\n        self.cat_processor = nn.Sequential(\n            nn.Linear(cat_total_dim, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.GELU(),\n            nn.Dropout(0.3)\n        )\n        \n        # === Numerical Processing with Mixture of Experts ===\n        self.num_experts = ExpertMixture(num_feat_dim, hidden_dim, num_experts=5)\n        \n        # === Feature Fusion ===\n        self.fusion = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.GELU(),\n            nn.Dropout(0.3)\n        )\n        \n        # === Self-Attention for Feature Recalibration ===\n        self.self_attn = nn.MultiheadAttention(\n            embed_dim=hidden_dim,\n            num_heads=8,\n            dropout=0.2,\n            batch_first=True\n        )\n        self.attn_norm = nn.LayerNorm(hidden_dim)\n        \n        # === Deep Feature Extractor ===\n        self.deep_features = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.GELU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.GELU(),\n            nn.Dropout(0.3)\n        )\n        \n        # === Prototype Layer ===\n        self.prototype_layer = PrototypeLayer(num_classes, hidden_dim)\n        \n        # === Contrastive Learning Head ===\n        self.contrastive_head = ContrastiveHead(hidden_dim, projection_dim=256)\n        \n        # === Auxiliary Classifier for Regularization ===\n        self.aux_classifier = nn.Linear(hidden_dim, num_classes)\n        \n    def forward(self, x_cat, x_num, return_features=False):\n        # Categorical embedding\n        cat_embeds = torch.cat([emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)], dim=-1)\n        cat_features = self.cat_processor(cat_embeds)\n        \n        # Numerical processing with experts\n        num_features, expert_weights = self.num_experts(x_num)\n        \n        # Fusion\n        fused = self.fusion(torch.cat([cat_features, num_features], dim=-1))\n        \n        # Self-attention (treating features as sequence of length 1)\n        fused_unsqueezed = fused.unsqueeze(1)\n        attn_out, _ = self.self_attn(fused_unsqueezed, fused_unsqueezed, fused_unsqueezed)\n        fused = self.attn_norm(fused + attn_out.squeeze(1))\n        \n        # Deep features\n        features = self.deep_features(fused)\n        \n        # Prototype-based logits\n        proto_logits = self.prototype_layer(features)\n        \n        # Auxiliary logits\n        aux_logits = self.aux_classifier(features)\n        \n        if return_features:\n            # Contrastive projections\n            projections = self.contrastive_head(features)\n            return proto_logits, aux_logits, features, projections\n        \n        return proto_logits, aux_logits\n\n# ===========================================\n# ADVANCED LOSS FUNCTIONS\n# ===========================================\n\nclass ClassBalancedFocalLoss(nn.Module):\n    \"\"\"Focal loss with class-balanced weighting using effective number of samples\"\"\"\n    def __init__(self, class_counts, beta=0.9999, gamma=2.0):\n        super().__init__()\n        effective_num = 1.0 - np.power(beta, class_counts)\n        weights = (1.0 - beta) / np.array(effective_num)\n        weights = weights / weights.sum() * len(weights)\n        self.weights = torch.tensor(weights, dtype=torch.float32)\n        self.gamma = gamma\n        \n    def forward(self, logits, targets):\n        self.weights = self.weights.to(logits.device)\n        ce_loss = F.cross_entropy(logits, targets, weight=self.weights, reduction='none')\n        pt = torch.exp(-ce_loss)\n        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n        return focal_loss.mean()\n\nclass SupConLoss(nn.Module):\n    \"\"\"Supervised Contrastive Loss\"\"\"\n    def __init__(self, temperature=0.07):\n        super().__init__()\n        self.temperature = temperature\n        \n    def forward(self, features, labels):\n        device = features.device\n        batch_size = features.shape[0]\n        \n        # Normalize features\n        features = F.normalize(features, dim=1)\n        \n        # Compute similarity matrix\n        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n        \n        # Create mask for positive pairs (same class)\n        labels = labels.contiguous().view(-1, 1)\n        mask = torch.eq(labels, labels.T).float().to(device)\n        \n        # Mask out self-similarity\n        logits_mask = torch.scatter(\n            torch.ones_like(mask),\n            1,\n            torch.arange(batch_size).view(-1, 1).to(device),\n            0\n        )\n        mask = mask * logits_mask\n        \n        # Compute log_prob\n        exp_logits = torch.exp(similarity_matrix) * logits_mask\n        log_prob = similarity_matrix - torch.log(exp_logits.sum(1, keepdim=True) + 1e-12)\n        \n        # Compute mean of log-likelihood over positive\n        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-12)\n        \n        loss = -mean_log_prob_pos.mean()\n        return loss\n\nclass CombinedLoss(nn.Module):\n    \"\"\"Multi-objective loss combining focal, contrastive, and consistency\"\"\"\n    def __init__(self, class_counts):\n        super().__init__()\n        self.focal_loss = ClassBalancedFocalLoss(class_counts, beta=0.9999, gamma=3.0)\n        self.supcon_loss = SupConLoss(temperature=0.07)\n        \n    def forward(self, proto_logits, aux_logits, targets, projections=None):\n        # Main prototype-based loss\n        loss_proto = self.focal_loss(proto_logits, targets)\n        \n        # Auxiliary loss for regularization\n        loss_aux = self.focal_loss(aux_logits, targets)\n        \n        # Consistency loss between two heads\n        loss_consistency = F.kl_div(\n            F.log_softmax(proto_logits, dim=1),\n            F.softmax(aux_logits, dim=1),\n            reduction='batchmean'\n        )\n        \n        total_loss = loss_proto + 0.5 * loss_aux + 0.3 * loss_consistency\n        \n        # Contrastive loss if projections provided\n        if projections is not None:\n            loss_contrastive = self.supcon_loss(projections, targets)\n            total_loss = total_loss + 0.5 * loss_contrastive\n            return total_loss, loss_proto, loss_aux, loss_consistency, loss_contrastive\n        \n        return total_loss, loss_proto, loss_aux, loss_consistency, torch.tensor(0.0)\n\n# ===========================================\n# DATASET WITH AGGRESSIVE RESAMPLING\n# ===========================================\n\nclass NSLDataset(Dataset):\n    def __init__(self, c, n, y):\n        self.c = torch.tensor(c, dtype=torch.long)\n        self.n = torch.tensor(n, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, i):\n        return self.c[i], self.n[i], self.y[i]\n\n# Create datasets\ntrain_dataset = NSLDataset(df_train[cat_cols].values, X_train_num, y_train)\ntest_dataset = NSLDataset(df_test[cat_cols].values, X_test_num, y_test)\n\n# CRITICAL: Aggressive resampling for rare classes\n# Use square root of inverse frequency for more balanced sampling\nclass_sample_counts = np.bincount(y_train)\nweights = 1.0 / np.sqrt(class_sample_counts[y_train])\nsampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, sampler=sampler, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=2)\n\n# ===========================================\n# MODEL INITIALIZATION\n# ===========================================\n\nmodel = MCDPAN(\n    cat_dims=cat_dims,\n    num_feat_dim=X_train_num.shape[1],\n    num_classes=len(le_target.classes_),\n    emb_dim=64,\n    hidden_dim=512\n).to(DEVICE)\n\nprint(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n# Optimizer with discriminative learning rates\nparam_groups = [\n    {'params': model.prototype_layer.parameters(), 'lr': 2e-3},  # Higher LR for prototypes\n    {'params': [p for n, p in model.named_parameters() if 'prototype' not in n], 'lr': 1e-3}\n]\noptimizer = torch.optim.AdamW(param_groups, weight_decay=1e-4)\n\n# Warm-up + Cosine scheduler\ndef lr_lambda(epoch):\n    if epoch < 5:\n        return (epoch + 1) / 5\n    else:\n        return 0.5 * (1 + math.cos(math.pi * (epoch - 5) / 45))\n\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n\n# Loss function\ncriterion = CombinedLoss(class_sample_counts)\n\n# ===========================================\n# TRAINING LOOP WITH CONTRASTIVE LEARNING\n# ===========================================\n\nbest_macro_f1 = 0.0\npatience = 20\npatience_counter = 0\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING STARTED\")\nprint(\"=\"*60)\n\nfor epoch in range(60):\n    # Training\n    model.train()\n    train_losses = {'total': 0, 'proto': 0, 'aux': 0, 'consistency': 0, 'contrastive': 0}\n    \n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/60\")\n    for batch_idx, (xc, xn, y) in enumerate(pbar):\n        xc, xn, y = xc.to(DEVICE), xn.to(DEVICE), y.to(DEVICE)\n        \n        optimizer.zero_grad()\n        \n        # Forward with contrastive learning every other batch\n        if batch_idx % 2 == 0:\n            proto_logits, aux_logits, features, projections = model(xc, xn, return_features=True)\n            loss, loss_p, loss_a, loss_c, loss_con = criterion(proto_logits, aux_logits, y, projections)\n        else:\n            proto_logits, aux_logits = model(xc, xn, return_features=False)\n            loss, loss_p, loss_a, loss_c, loss_con = criterion(proto_logits, aux_logits, y)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        train_losses['total'] += loss.item()\n        train_losses['proto'] += loss_p.item()\n        train_losses['aux'] += loss_a.item()\n        train_losses['consistency'] += loss_c.item()\n        train_losses['contrastive'] += loss_con.item() if isinstance(loss_con, torch.Tensor) else 0\n        \n        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    scheduler.step()\n    \n    # Average losses\n    for k in train_losses:\n        train_losses[k] /= len(train_loader)\n    \n    # Validation\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_proto_preds = []\n    \n    with torch.no_grad():\n        for xc, xn, y in test_loader:\n            xc, xn = xc.to(DEVICE), xn.to(DEVICE)\n            proto_logits, aux_logits = model(xc, xn, return_features=False)\n            \n            # Ensemble: average both heads\n            ensemble_logits = (proto_logits + aux_logits) / 2\n            preds = torch.argmax(ensemble_logits, dim=1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y.numpy())\n    \n    # Metrics\n    macro_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n    weighted_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n    per_class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\n    \n    # Count classes with F1 > 0.3\n    good_classes = np.sum(per_class_f1 > 0.3)\n    \n    print(f\"\\nEpoch {epoch+1}:\")\n    print(f\"  Loss - Total: {train_losses['total']:.4f}, Proto: {train_losses['proto']:.4f}, \"\n          f\"Aux: {train_losses['aux']:.4f}, Consist: {train_losses['consistency']:.4f}, \"\n          f\"Contr: {train_losses['contrastive']:.4f}\")\n    print(f\"  Macro F1: {macro_f1:.4f} | Weighted F1: {weighted_f1:.4f}\")\n    print(f\"  Classes with F1 > 0.3: {good_classes}/{len(le_target.classes_)}\")\n    \n    # Early stopping based on macro F1\n    if macro_f1 > best_macro_f1:\n        best_macro_f1 = macro_f1\n        patience_counter = 0\n        torch.save({\n            'model': model.state_dict(),\n            'epoch': epoch,\n            'macro_f1': macro_f1\n        }, 'best_mcdpan_model.pth')\n        print(f\"  ✓ New best Macro F1: {best_macro_f1:.4f}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n            break\n\n# ===========================================\n# FINAL EVALUATION\n# ===========================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"LOADING BEST MODEL FOR FINAL EVALUATION\")\nprint(\"=\"*70)\n\ncheckpoint = torch.load('best_mcdpan_model.pth')\nmodel.load_state_dict(checkpoint['model'])\nmodel.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for xc, xn, y in test_loader:\n        xc, xn = xc.to(DEVICE), xn.to(DEVICE)\n        proto_logits, aux_logits = model(xc, xn, return_features=False)\n        ensemble_logits = (proto_logits + aux_logits) / 2\n        preds = torch.argmax(ensemble_logits, dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(y.numpy())\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL CLASSIFICATION REPORT\")\nprint(\"=\"*70 + \"\\n\")\nprint(classification_report(all_labels, all_preds, target_names=le_target.classes_, \n                          zero_division=0, digits=4))\n\nper_class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\nprint(\"\\n\" + \"=\"*70)\nprint(\"PER-CLASS F1 SCORES\")\nprint(\"=\"*70)\nfor class_name, f1 in zip(le_target.classes_, per_class_f1):\n    marker = \"✓\" if f1 > 0.5 else (\"⚠\" if f1 > 0.3 else \"✗\")\n    print(f\"{marker} {class_name:20s}: {f1:.4f}\")\n\nprint(f\"\\n{'='*70}\")\nprint(f\"BEST MACRO F1 ACHIEVED: {best_macro_f1:.4f}\")\nprint(f\"Classes with F1 > 0.5: {np.sum(per_class_f1 > 0.5)}/{len(per_class_f1)}\")\nprint(f\"Classes with F1 > 0.3: {np.sum(per_class_f1 > 0.3)}/{len(per_class_f1)}\")\nprint(f\"{'='*70}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:23:30.288246Z","iopub.execute_input":"2026-01-17T10:23:30.288620Z","iopub.status.idle":"2026-01-17T11:00:37.682417Z","shell.execute_reply.started":"2026-01-17T10:23:30.288585Z","shell.execute_reply":"2026-01-17T11:00:37.681377Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n\nClass distribution in training:\nback                :    24258 samples\nbuffer_overflow     :    24258 samples\nftp_write           :    24258 samples\nguess_passwd        :    24258 samples\nimap                :    24258 samples\nipsweep             :    24258 samples\nland                :    24258 samples\nloadmodule          :    24258 samples\nmultihop            :    24258 samples\nneptune             :    24258 samples\nnmap                :    24258 samples\nnormal              :    24258 samples\nperl                :    24258 samples\nphf                 :    24258 samples\npod                 :    24258 samples\nportsweep           :    24258 samples\nrootkit             :    24258 samples\nsatan               :    24258 samples\nsmurf               :    24258 samples\nspy                 :    24258 samples\nteardrop            :    24258 samples\nwarezclient         :    24258 samples\nwarezmaster         :    24258 samples\n\nModel parameters: 4,051,163\n\n============================================================\nTRAINING STARTED\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.73it/s, loss=0.8337]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1:\n  Loss - Total: 0.5964, Proto: 0.0684, Aux: 0.0723, Consist: 0.0097, Contr: 0.9778\n  Macro F1: 0.4134 | Weighted F1: 0.8061\n  Classes with F1 > 0.3: 11/23\n  ✓ New best Macro F1: 0.4134\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/60: 100%|██████████| 4359/4359 [01:07<00:00, 65.00it/s, loss=0.9549]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2:\n  Loss - Total: 0.5300, Proto: 0.0409, Aux: 0.0407, Consist: 0.0022, Contr: 0.9361\n  Macro F1: 0.4064 | Weighted F1: 0.8055\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.26it/s, loss=0.8056]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3:\n  Loss - Total: 0.5143, Proto: 0.0350, Aux: 0.0351, Consist: 0.0022, Contr: 0.9222\n  Macro F1: 0.4206 | Weighted F1: 0.8011\n  Classes with F1 > 0.3: 12/23\n  ✓ New best Macro F1: 0.4206\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.76it/s, loss=0.8453]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4:\n  Loss - Total: 0.5043, Proto: 0.0312, Aux: 0.0317, Consist: 0.0027, Contr: 0.9129\n  Macro F1: 0.3990 | Weighted F1: 0.7994\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.72it/s, loss=0.7841]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5:\n  Loss - Total: 0.4962, Proto: 0.0283, Aux: 0.0290, Consist: 0.0030, Contr: 0.9050\n  Macro F1: 0.4498 | Weighted F1: 0.8038\n  Classes with F1 > 0.3: 12/23\n  ✓ New best Macro F1: 0.4498\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.81it/s, loss=0.7530]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6:\n  Loss - Total: 0.4840, Proto: 0.0237, Aux: 0.0243, Consist: 0.0027, Contr: 0.8947\n  Macro F1: 0.4252 | Weighted F1: 0.8093\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.87it/s, loss=0.8368]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7:\n  Loss - Total: 0.4763, Proto: 0.0213, Aux: 0.0219, Consist: 0.0026, Contr: 0.8866\n  Macro F1: 0.4142 | Weighted F1: 0.8011\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.98it/s, loss=0.8307]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8:\n  Loss - Total: 0.4681, Proto: 0.0183, Aux: 0.0189, Consist: 0.0024, Contr: 0.8792\n  Macro F1: 0.4276 | Weighted F1: 0.8166\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.10it/s, loss=0.7779]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9:\n  Loss - Total: 0.4639, Proto: 0.0171, Aux: 0.0176, Consist: 0.0023, Contr: 0.8747\n  Macro F1: 0.4340 | Weighted F1: 0.8137\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.91it/s, loss=0.7577]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10:\n  Loss - Total: 0.4598, Proto: 0.0156, Aux: 0.0162, Consist: 0.0023, Contr: 0.8709\n  Macro F1: 0.4202 | Weighted F1: 0.8224\n  Classes with F1 > 0.3: 13/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.07it/s, loss=0.8084]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11:\n  Loss - Total: 0.4562, Proto: 0.0145, Aux: 0.0150, Consist: 0.0022, Contr: 0.8669\n  Macro F1: 0.4352 | Weighted F1: 0.8148\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.18it/s, loss=0.7097]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12:\n  Loss - Total: 0.4533, Proto: 0.0134, Aux: 0.0138, Consist: 0.0021, Contr: 0.8647\n  Macro F1: 0.3929 | Weighted F1: 0.7942\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.98it/s, loss=0.8041]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13:\n  Loss - Total: 0.4506, Proto: 0.0127, Aux: 0.0131, Consist: 0.0021, Contr: 0.8614\n  Macro F1: 0.4591 | Weighted F1: 0.8217\n  Classes with F1 > 0.3: 12/23\n  ✓ New best Macro F1: 0.4591\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.60it/s, loss=0.7132]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14:\n  Loss - Total: 0.4474, Proto: 0.0117, Aux: 0.0120, Consist: 0.0020, Contr: 0.8582\n  Macro F1: 0.4172 | Weighted F1: 0.8186\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.28it/s, loss=0.7743]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15:\n  Loss - Total: 0.4448, Proto: 0.0109, Aux: 0.0112, Consist: 0.0019, Contr: 0.8555\n  Macro F1: 0.4214 | Weighted F1: 0.8133\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.07it/s, loss=0.8091]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16:\n  Loss - Total: 0.4430, Proto: 0.0104, Aux: 0.0107, Consist: 0.0018, Contr: 0.8533\n  Macro F1: 0.4438 | Weighted F1: 0.8136\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.24it/s, loss=0.8368]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17:\n  Loss - Total: 0.4420, Proto: 0.0099, Aux: 0.0102, Consist: 0.0018, Contr: 0.8531\n  Macro F1: 0.4449 | Weighted F1: 0.8171\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.14it/s, loss=0.7687]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18:\n  Loss - Total: 0.4388, Proto: 0.0090, Aux: 0.0094, Consist: 0.0017, Contr: 0.8492\n  Macro F1: 0.3919 | Weighted F1: 0.8092\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.89it/s, loss=0.7218]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19:\n  Loss - Total: 0.4382, Proto: 0.0088, Aux: 0.0091, Consist: 0.0016, Contr: 0.8486\n  Macro F1: 0.4314 | Weighted F1: 0.8166\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/60: 100%|██████████| 4359/4359 [01:07<00:00, 64.90it/s, loss=0.8767]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20:\n  Loss - Total: 0.4362, Proto: 0.0082, Aux: 0.0085, Consist: 0.0016, Contr: 0.8464\n  Macro F1: 0.4206 | Weighted F1: 0.8063\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.42it/s, loss=0.8597]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 21:\n  Loss - Total: 0.4349, Proto: 0.0079, Aux: 0.0081, Consist: 0.0015, Contr: 0.8450\n  Macro F1: 0.4194 | Weighted F1: 0.8104\n  Classes with F1 > 0.3: 12/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.35it/s, loss=0.7385]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 22:\n  Loss - Total: 0.4336, Proto: 0.0075, Aux: 0.0077, Consist: 0.0014, Contr: 0.8436\n  Macro F1: 0.4217 | Weighted F1: 0.8209\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.45it/s, loss=0.8657]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23:\n  Loss - Total: 0.4317, Proto: 0.0070, Aux: 0.0073, Consist: 0.0014, Contr: 0.8412\n  Macro F1: 0.4194 | Weighted F1: 0.8159\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.29it/s, loss=0.7939]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 24:\n  Loss - Total: 0.4307, Proto: 0.0066, Aux: 0.0068, Consist: 0.0013, Contr: 0.8406\n  Macro F1: 0.4195 | Weighted F1: 0.8173\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.59it/s, loss=0.7235]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25:\n  Loss - Total: 0.4293, Proto: 0.0062, Aux: 0.0063, Consist: 0.0013, Contr: 0.8391\n  Macro F1: 0.4178 | Weighted F1: 0.8053\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.56it/s, loss=0.8943]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26:\n  Loss - Total: 0.4280, Proto: 0.0059, Aux: 0.0061, Consist: 0.0012, Contr: 0.8375\n  Macro F1: 0.4185 | Weighted F1: 0.8068\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.32it/s, loss=0.7256]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 27:\n  Loss - Total: 0.4269, Proto: 0.0058, Aux: 0.0059, Consist: 0.0011, Contr: 0.8357\n  Macro F1: 0.4136 | Weighted F1: 0.8055\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.36it/s, loss=0.7142]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28:\n  Loss - Total: 0.4259, Proto: 0.0053, Aux: 0.0055, Consist: 0.0011, Contr: 0.8350\n  Macro F1: 0.4174 | Weighted F1: 0.8145\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.76it/s, loss=0.7897]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29:\n  Loss - Total: 0.4244, Proto: 0.0050, Aux: 0.0052, Consist: 0.0010, Contr: 0.8330\n  Macro F1: 0.4225 | Weighted F1: 0.8205\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.77it/s, loss=0.7251]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30:\n  Loss - Total: 0.4237, Proto: 0.0048, Aux: 0.0049, Consist: 0.0009, Contr: 0.8324\n  Macro F1: 0.4221 | Weighted F1: 0.8177\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.82it/s, loss=0.7664]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 31:\n  Loss - Total: 0.4229, Proto: 0.0047, Aux: 0.0048, Consist: 0.0009, Contr: 0.8310\n  Macro F1: 0.4187 | Weighted F1: 0.8073\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.52it/s, loss=0.7124]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 32:\n  Loss - Total: 0.4215, Proto: 0.0042, Aux: 0.0043, Consist: 0.0008, Contr: 0.8298\n  Macro F1: 0.4401 | Weighted F1: 0.8201\n  Classes with F1 > 0.3: 11/23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/60: 100%|██████████| 4359/4359 [01:06<00:00, 65.51it/s, loss=0.7916]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 33:\n  Loss - Total: 0.4209, Proto: 0.0041, Aux: 0.0042, Consist: 0.0008, Contr: 0.8289\n  Macro F1: 0.4389 | Weighted F1: 0.8022\n  Classes with F1 > 0.3: 11/23\n\nEarly stopping at epoch 33\n\n======================================================================\nLOADING BEST MODEL FOR FINAL EVALUATION\n======================================================================\n\n======================================================================\nFINAL CLASSIFICATION REPORT\n======================================================================\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_347/3067182258.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FINAL CLASSIFICATION REPORT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m print(classification_report(all_labels, all_preds, target_names=le_target.classes_, \n\u001b[0m\u001b[1;32m    514\u001b[0m                           zero_division=0, digits=4))\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2691\u001b[0m             )\n\u001b[1;32m   2692\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2694\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Number of classes, 22, does not match size of target_names, 23. Try specifying the labels parameter"],"ename":"ValueError","evalue":"Number of classes, 22, does not match size of target_names, 23. Try specifying the labels parameter","output_type":"error"}],"execution_count":10}]}