{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-17T11:57:30.177192Z",
     "iopub.status.busy": "2026-01-17T11:57:30.176866Z",
     "iopub.status.idle": "2026-01-17T11:57:30.207055Z",
     "shell.execute_reply": "2026-01-17T11:57:30.206368Z",
     "shell.execute_reply.started": "2026-01-17T11:57:30.177145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nsl-kdd-augmented/smote_augmented.csv\n",
      "/kaggle/input/nslkdd/KDDTest+.arff\n",
      "/kaggle/input/nslkdd/KDDTest-21.arff\n",
      "/kaggle/input/nslkdd/KDDTest1.jpg\n",
      "/kaggle/input/nslkdd/KDDTrain+.txt\n",
      "/kaggle/input/nslkdd/KDDTrain+_20Percent.txt\n",
      "/kaggle/input/nslkdd/KDDTest-21.txt\n",
      "/kaggle/input/nslkdd/KDDTest+.txt\n",
      "/kaggle/input/nslkdd/KDDTrain+.arff\n",
      "/kaggle/input/nslkdd/index.html\n",
      "/kaggle/input/nslkdd/KDDTrain+_20Percent.arff\n",
      "/kaggle/input/nslkdd/KDDTrain1.jpg\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTest+.arff\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTest-21.arff\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTest1.jpg\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTrain+.txt\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTrain+_20Percent.txt\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTest-21.txt\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTest+.txt\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTrain+.arff\n",
      "/kaggle/input/nslkdd/nsl-kdd/index.html\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTrain+_20Percent.arff\n",
      "/kaggle/input/nslkdd/nsl-kdd/KDDTrain1.jpg\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T13:33:21.443309Z",
     "iopub.status.busy": "2026-01-17T13:33:21.442725Z",
     "iopub.status.idle": "2026-01-17T13:33:22.321091Z",
     "shell.execute_reply": "2026-01-17T13:33:22.320321Z",
     "shell.execute_reply.started": "2026-01-17T13:33:21.443278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing PSMG-Net Final Fusion...\n",
      "\n",
      "--- PSMG-Net Q1 FINAL RESULTS ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           back       1.00      0.95      0.98       359\n",
      "buffer_overflow       0.12      0.05      0.07        20\n",
      "      ftp_write       0.01      0.33      0.02         3\n",
      "   guess_passwd       0.85      0.38      0.53      1231\n",
      "           imap       0.00      0.00      0.00         1\n",
      "        ipsweep       0.99      0.99      0.99       141\n",
      "           land       1.00      1.00      1.00         7\n",
      "     loadmodule       0.00      0.00      0.00         2\n",
      "       multihop       0.00      0.00      0.00        18\n",
      "        neptune       1.00      1.00      1.00      4657\n",
      "           nmap       1.00      1.00      1.00        73\n",
      "         normal       0.90      0.97      0.93      9711\n",
      "           perl       0.20      0.50      0.29         2\n",
      "            phf       0.00      0.00      0.00         2\n",
      "            pod       0.72      0.95      0.82        41\n",
      "      portsweep       0.76      0.96      0.85       157\n",
      "        rootkit       0.06      0.15      0.09        13\n",
      "          satan       0.82      1.00      0.90       735\n",
      "          smurf       1.00      1.00      1.00       665\n",
      "       teardrop       0.24      1.00      0.39        12\n",
      "    warezclient       0.00      0.00      0.00         0\n",
      "    warezmaster       0.94      0.43      0.59       944\n",
      "\n",
      "       accuracy                           0.91     18794\n",
      "      macro avg       0.53      0.58      0.52     18794\n",
      "   weighted avg       0.92      0.91      0.90     18794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# ===========================================\n",
    "# 1️⃣ Path A: The PSMG Specialist (Updated Logic)\n",
    "# ===========================================\n",
    "def final_psmg_fusion(X_proc, df_orig):\n",
    "    model_lso.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model_lso(torch.tensor(X_proc, dtype=torch.float32).to(device))\n",
    "        # Tempering: Sharpen the attack signals\n",
    "        probs_l = torch.softmax(logits * 1.5, dim=1).cpu().numpy()\n",
    "    \n",
    "    probs_x = anchor_model.predict_proba(X_proc)\n",
    "    final_preds = []\n",
    "    \n",
    "    # Pre-calculated Indices\n",
    "    idx_back = le.transform(['back'])[0]\n",
    "    u2r_idx = [le.transform([c])[0] for c in ['rootkit', 'buffer_overflow', 'loadmodule', 'perl']]\n",
    "    r2l_idx = [le.transform([c])[0] for c in ['guess_passwd', 'warezmaster', 'ftp_write']]\n",
    "\n",
    "    for i in range(len(X_proc)):\n",
    "        p_l = probs_l[i]\n",
    "        p_x = probs_x[i]\n",
    "        protocol = df_orig['protocol_type'].iloc[i]\n",
    "        \n",
    "        # --- RULE 1: THE DOS ANCHOR (Fixing 'Back') ---\n",
    "        # If XGBoost is very confident in 'back' and bytes are high, LOCK IT.\n",
    "        if p_x[idx_back] > 0.4 and df_orig['src_bytes'].iloc[i] > 5000:\n",
    "            final_preds.append(idx_back)\n",
    "            \n",
    "        # --- RULE 2: U2R PROTOCOL GUARD ---\n",
    "        # User-to-Root usually involves specific flags\n",
    "        elif (df_orig['root_shell'].iloc[i] > 0 or df_orig['num_root'].iloc[i] > 0) and protocol == 'tcp':\n",
    "            final_preds.append(u2r_idx[np.argmax(p_l[u2r_idx])])\n",
    "            \n",
    "        # --- RULE 3: R2L CONTENT GUARD ---\n",
    "        elif (df_orig['num_failed_logins'].iloc[i] > 0 or df_orig['hot'].iloc[i] > 0):\n",
    "            # Pick the strongest R2L signal\n",
    "            final_preds.append(r2l_idx[np.argmax(p_l[r2l_idx])])\n",
    "            \n",
    "        # --- RULE 4: STABILITY GATE ---\n",
    "        elif np.max(p_x) > 0.95:\n",
    "            final_preds.append(np.argmax(p_x))\n",
    "            \n",
    "        # --- DEFAULT: Weighted Majority ---\n",
    "        else:\n",
    "            # Shift balance toward Specialist for residual samples\n",
    "            final_preds.append(np.argmax(0.5 * p_x + 0.5 * p_l))\n",
    "            \n",
    "    return np.array(final_preds)\n",
    "\n",
    "# ===========================================\n",
    "# 2️⃣ Execution\n",
    "# ===========================================\n",
    "print(\"Executing PSMG-Net Final Fusion...\")\n",
    "final_preds = final_psmg_fusion(X_test_proc, df_test)\n",
    "\n",
    "unique_test_classes = np.unique(np.concatenate([y_test_enc, final_preds]))\n",
    "target_names = [le.classes_[i] for i in unique_test_classes]\n",
    "\n",
    "print(\"\\n--- PSMG-Net Q1 FINAL RESULTS ---\")\n",
    "print(classification_report(y_test_enc, final_preds, \n",
    "                            labels=unique_test_classes, \n",
    "                            target_names=target_names, \n",
    "                            zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 174616,
     "sourceId": 394223,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9276062,
     "sourceId": 14523807,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
